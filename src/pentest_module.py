import json
import pickle
import os
import textwrap
import time
import sys
import subprocess
import pexpect
from cvss import CVSS3

from src.prompt_class import PromptStore
from src.agent_import import dynamic_import
from attack_state import attackState, attackPath
from rag import RAG_module
      
        
class pentest_module:

    def __init__(self, reasoning_model="gpt-4-turbo", parsing_model="gpt-3.5-turbo", log_dir="logs", instructor_dir="docs"):

        self.log_dir = log_dir
        
        self.planner= dynamic_import(reasoning_model)
        self.executor = dynamic_import(reasoning_model)
        self.summarizer = dynamic_import(parsing_model)
        self.extractor = dynamic_import(parsing_model)
        self.instructor = RAG_module(document_path = instructor_dir)

        self.prompts = PromptStore()
        self.history = {"penheal": [], "console": [], "user": []}

        self.all_paths = []
        self.counterfactual_prompt = ""

    def initialize(self):
        
        # initialize the agents
        (_, self.executor_id) = self.executor.send_new_message(self.prompts.task_session_init)
        (_, self.planner_id) = self.planner.send_new_message(self.prompts.planner_prompt)
        (_, self.summarizer_id) = self.summarizer.send_new_message(self.prompts.summarizer_prompt)
        (_, self.extractor_id) = self.extractor.send_new_message(self.prompts.extractor_prompt)

        # take in user input
        init_description = input("Please describe the penetration testing task in one line, including the target IP, task type, etc.\n>")
        self.history["user"].append(init_description)
        
        prefixed_init_description = self.prompts.task_description + init_description
        print("Constructing Initial Attack Plan...")
        attack_plan_raw = self.planner.send_message(prefixed_init_description, self.planner_id)
        attack_plan = attack_plan_raw.split("$")[0]
        print("Initial attack tree:")
        print(attack_plan)
        self.history["penheal"].append(attack_plan)
        state = attackState(attack_plan=attack_plan, target=init_description)
        return state

    def summarize_result(self, text) -> str:
        prompt = "Here is the content to be summarized: "

        text = " ".join(text)
        
        # The default token-size limit is 4096 (web UI even shorter). 1 token ~= 4 chars in English
        # Use textwrap to split inputs. Limit to 2000 token (8000 chars) for each input
        # (1) replace all the newlines with spaces
        text = text.replace("\r", " ").replace("\n", " ")
        # (2) wrap the text
        wrapped_text = textwrap.fill(text, 8000)
        wrapped_inputs = wrapped_text.split("\n")
        # (3) send the inputs to chatGPT input_parsing_session and obtain the results
        summarized_content = ""
        for wrapped_input in wrapped_inputs:
            word_limit = f"Please ensure that the input is less than {8000 / len(wrapped_inputs)} words.\n"
            summarized_content += self.summarizer.send_message(
                prompt + word_limit + wrapped_input, self.summarizer_id
            )
        # log the conversation
        #self.log_conversation("input_parsing", summarized_content)
        return summarized_content
    
    def update_attack_plan(self, state):
        prompt = self.prompts.update_attack_plan_prompt
        content = f"Previous command: {state.prev_command}\nPrevious result: {state.prev_result}"
        new_attack_plan = self.planner.send_message(prompt + content, self.planner_id)
        return new_attack_plan

    def get_exact_command(self, state):
        prompt = self.prompts.get_exact_command_prompt
        excerpt_list = self.instructor.ask_question(state.attack_plan)
        content = f"Here is the attack plan: {state.attack_plan}\n Here is a brief introduction to the task: {state.target}\n"
        instruction = "Here is some info from the knowledge base for your reference:"
        for excerpt in excerpt_list:
            instruction += "\n" + excerpt
        commands = self.executor.send_message(prompt + content + instruction, self.executor_id)
        return commands

    def execute_command(self, command_list):

        print("Lists of commands to be executed: ")
        for command in command_list:
            print(command)
        
        # devide the command_list into 2 parts: msfconsole and others
        msf_list = []
        other_list = []
        for command in command_list:
            if "msfconsole" in command:
                msf_list.append(command)
            else:
                other_list.append(command)

        result_list = []
        if len(msf_list) > 0:
            marker = r'\x1b\[.*>'
            child = pexpect.spawn("/opt/metasploit-framework/bin/msfconsole -q")
            # child.logfile = open("mylog", "w")
            child.expect(marker)
            for command in msf_list:
                actual_command = command.split("msfconsole: ")[1].strip()
                print("executing command: ", actual_command)
                child.sendline(actual_command)
                time.sleep(4)
                child.expect(marker)
                print("Command executed successfully: ")
                print(child.after.decode("utf-8").strip())
                result_list.append(child.after.decode("utf-8").strip())
                self.history["pentestGPT"].append(actual_command)
                self.history["console"].append(child.after.decode("utf-8").strip())
            child.sendline("exit -y")
            
        for command in other_list:  
            if "telnet" in command:
                res = ""
                child = pexpect.spawn(command)
                child.expect('.*#')
                res += child.before.decode()
                res += child.after.decode()
                child.sendline('whoami')
                child.expect('.*t')
                res += child.before.decode()
                res += child.after.decode()

                child.sendline('exit')
                child.close()
                result_list.append(res)
                result_list.append(result)
            else:
                try:
                    print(f"Executing command: {command}")
                    result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                    result_list.append(result.stdout)
                    print("Command executed successfully: ")
                    print(result.stdout)
                    self.history["console"].append(result.stdout)
                except subprocess.CalledProcessError as e:
                    print(f"Error executing command: {e}")
                    print(f"Stderr: {e.stderr}")
                    result_list.append(e.stderr)
                    self.history["console"].append(e.stderr)
            self.history["pentestGPT"].append(command)
        return result_list

    def input_handler(self, state) -> str: 

        # 0. Summarize the previous command and result
        if state.prev_command:
            print(f"Previous command: {state.prev_command}")
            if "nmap --script vuln" in state.prev_command:
                summarized_prev_result = self.prompts.summarized_scan_result
            else:
                summarized_prev_result = self.summarize_result(state.prev_result)
            state.prev_result = summarized_prev_result
            print("Summarized previous result: ")
            print(summarized_prev_result)

            # 1. Update the attack tree
            new_attack_plan = self.update_attack_plan(state)
            if "!Attack successful!" in new_attack_plan:
                print("Attack successful! Exiting the session...")
                return None
            state.attack_plan = new_attack_plan
            print("Updated attack tree: ")
            print(new_attack_plan)
        
        if not state.prev_command and self.count > 0: # the first conversation of the session
            print("refreshing counterfactual prompt")
            alter_init_prompt = self.refresh_counterfactual_prompt()
            new_attack_plan = self.planner.send_message(alter_init_prompt, self.planner_id)
            state.attack_plan = new_attack_plan
            print("Updated attack tree after counterfactual prompt: ")
            print(new_attack_plan)
 
        # 2. Get the command to be executed
        commands = self.get_exact_command(state)
        command_list = commands.split("$")[:-1]

        # 3. Execute the command
        result_list = self.execute_command(command_list)
        updated_state = attackState(attack_plan=state.attack_plan, target=state.target, prev_command=commands, prev_result=result_list)
        return updated_state

    def pentest_given_state(self, init_state):

        state_list = [init_state]
        state = init_state
        # enter the main loop.
        while True:
            # update the state
            state = self.input_handler(state)
            if not state:  # end the session
                break
            state_list.append(state)
            
        # log the session. Save self.history into a txt file based on timestamp
        timestamp = time.time()
        log_name = f"pentestGPT_log_{str(timestamp)}.txt"
        # save it in the logs folder
        log_path = os.path.join(self.log_dir, log_name)
        with open(log_path, "w") as f:
            json.dump(self.history, f)

        return state_list, state_list[-2].attack_plan
    
    def refresh_counterfactual_prompt(self):
        for path in self.all_paths:
            if len(path.vul) == 0:
                path.get_vul(self.extractor, self.extractor_id)
            print("Vul used ")
            print(path.vul)
        
        counterfactual_prompt = "Here is the list of vulnerabilities already identified, please mark them as completed on the attack list. Try to exploit the system as if they do not exist: \n"
        for i, path in enumerate(self.all_paths):
            counterfactual_prompt += str(i+1) + ". " + path.vul + "\n"
        self.counterfactual_prompt = counterfactual_prompt
        print("Alternate instruction: ")
        print(counterfactual_prompt)
        return counterfactual_prompt
    
    def makeup_pentest(self,vuln_info_path):
        # load the paths from the file
        print("Starting the additional pentest session...")
        with open(vuln_info_path, "rb") as f:
            self.potential_paths = pickle.load(f)
        
        # update the attack plan with the vulnerabilities mentioned
        # first get the vulnerabilities from the paths
        path_summaries = ""
        for i, path in enumerate(self.potential_paths):
            path_summaries += str(i+1) + ". " + path.get_cve_id() + "\n"
        
        prompt = "Please create an attack plan based on the potential vulnerabilities described above\n"
        updated_attack_plan = self.planner.send_message(prompt + path_summaries, self.planner_id)
        print("Updated attack tree: ")
        print(updated_attack_plan)
        
        init_state = self.initialize()
        for self.count in range(20):
            # initialize alternate instruction
            print(f"Exploring path {self.count + 1}")
            if self.count > 0:
                init_state.attack_plan = updated_attack_plan
            state_list, updated_attack_plan = self.pentest_given_state(init_state)
            cur_path = attackPath(state_list, self.extractor, self.extractor_id)
            self.all_paths.append(cur_path)
            
            # dump the paths into a file for future reference
            log_path = self.log_dir + "/additional.pkl"
            # save it in the logs folder
            with open(log_path, "wb") as f:
                pickle.dump(self.all_paths, f)
            
            # Ask if the user wants to exit
            exit_prompt = "Do you want to continue the session? (yes/no): "
            exit = input(exit_prompt)
            if "n" in exit:
                break
        return self.all_paths

    def extract_IP(self):
        # tell the planner to extract the IP address
        text = "Please extract the IP address from the given text in the format $IP$"
        ip_string = self.extractor.send_message(text, self.extractor_id)
        ip = ip_string.split("$")[1]
        return ip
    
    def main(self):
        # Ask for the user's request (target IP) and get the attack tree
        init_state = self.initialize()
        updated_attack_plan = None
        for self.count in range(20):
            # initialize alternate instruction
            print(f"Exploring path {self.count + 1}")
            if self.count > 0:
                init_state.attack_plan = updated_attack_plan
            state_list, updated_attack_plan = self.pentest_given_state(init_state)
            cur_path = attackPath(state_list, self.extractor, self.extractor_id)
            self.all_paths.append(cur_path)
            
            # dump the paths into a file for future reference
            log_path = self.log_dir + "/raw.pkl"
            # save it in the logs folder
            with open(log_path, "wb") as f:
                pickle.dump(self.all_paths, f)
            
            # Ask if the user wants to exit
            exit_prompt = "Do you want to continue the session? (yes/no): "
            exit = input(exit_prompt)
            if "n" in exit:
                break
            
if __name__ == "__main__":

    pentest_module = pentest_module(reasoning_model="gpt-4-turbo", parsing_model="gpt-3.5-turbo", log_dir="logs")
    pentest_module.main()
